import React, { useEffect, useState } from 'react';
import { View, Text, StyleSheet, ScrollView, TouchableOpacity, Alert, Platform, NativeModules, Modal } from 'react-native';
import { Ionicons } from '@expo/vector-icons';
import { useRouter } from 'expo-router';
import AudioButton from '../../../components/AudioButton';
import * as Speech from 'expo-speech';
import AsyncStorage from '@react-native-async-storage/async-storage';
import Voice from '@react-native-voice/voice';
import { WebView } from 'react-native-webview';
import { requestMicrophonePermission } from '../../../../utils/requestMicrophonePermission';

export default function ExpresionOral() {
  const router = useRouter();
  const [saved, setSaved] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [currentExample, setCurrentExample] = useState<number | null>(null);
  const [exampleTranscripts, setExampleTranscripts] = useState<string[]>([]);
  const [lastVoiceError, setLastVoiceError] = useState<string>('');
  const [nativeInfo, setNativeInfo] = useState<string>('');
  const [compatMode, setCompatMode] = useState<boolean>(false);
  const [webMode, setWebMode] = useState<boolean>(false);
  const [webPromptText, setWebPromptText] = useState<string>('');
  const [webPercent, setWebPercent] = useState<number | null>(null);

  const prompts = [
    {
      es: 'PresÃ©ntate (nombre, edad, paÃ­s)',
      ar: 'Ù‚Ø¯Ù‘Ù… Ù†ÙØ³Ùƒ (Ø§Ù„Ø§Ø³Ù…ØŒ Ø§Ù„Ø¹Ù…Ø±ØŒ Ø§Ù„Ø¨Ù„Ø¯)',
      audio: 'Me llamo Ahmed, tengo 28 aÃ±os y soy de Argelia.'
    },
    {
      es: 'Habla de tu familia (padres, hermanos, con quiÃ©n vives)',
      ar: 'ØªØ­Ø¯Ø« Ø¹Ù† Ø¹Ø§Ø¦Ù„ØªÙƒ (Ø§Ù„ÙˆØ§Ù„Ø¯Ø§Ù†ØŒ Ø§Ù„Ø¥Ø®ÙˆØ©ØŒ Ù…Ø¹ Ù…Ù† ØªØ¹ÙŠØ´)',
      audio: 'Vivo con mi familia. Tengo un hermano y una hermana.'
    },
    {
      es: 'Describe tu casa (habitaciones principales)',
      ar: 'ØµÙ Ø¨ÙŠØªÙƒ (Ø§Ù„ØºØ±Ù Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©)',
      audio: 'Mi casa tiene salÃ³n, cocina, baÃ±o y dos dormitorios.'
    },
    {
      es: 'Cuenta quÃ© haces en tu tiempo libre',
      ar: 'Ø§Ø­Ù’ÙƒÙ Ù…Ø§Ø°Ø§ ØªÙØ¹Ù„ ÙÙŠ ÙˆÙ‚Øª ÙØ±Ø§ØºÙƒ',
      audio: 'En mi tiempo libre leo y escucho mÃºsica.'
    },
    {
      es: 'Pide indicaciones para llegar a un lugar',
      ar: 'Ø§Ø·Ù„Ø¨ Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ù„Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ù…ÙƒØ§Ù†',
      audio: 'Disculpe, Â¿cÃ³mo llego a la estaciÃ³n?'
    },
    {
      es: 'Di cÃ³mo te sientes y si necesitas ayuda mÃ©dica',
      ar: 'Ù‚Ù„ ÙƒÙŠÙ ØªØ´Ø¹Ø± ÙˆØ¥Ø°Ø§ ÙƒÙ†Øª ØªØ­ØªØ§Ø¬ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø·Ø¨ÙŠØ©',
      audio: 'No me siento bien. Me duele la cabeza.'
    },
    {
      es: 'Habla del clima de hoy y de tu estaciÃ³n favorita',
      ar: 'ØªØ­Ø¯Ø« Ø¹Ù† Ø·Ù‚Ø³ Ø§Ù„ÙŠÙˆÙ… ÙˆÙØµÙ„Ùƒ Ø§Ù„Ù…ÙØ¶Ù„',
      audio: 'Hoy hace sol. Mi estaciÃ³n favorita es la primavera.'
    },
  ];

  // Reconocimiento de voz: configurar listeners y limpieza
  useEffect(() => {
    try {
      const hasModule = !!(NativeModules as any)?.Voice;
      const keys = Object.keys((NativeModules as any) || {});
      setNativeInfo(`Platform: ${Platform.OS} ${Platform.Version} | VoiceModule: ${hasModule ? 'PRESENT' : 'NULL'} | Modules: ${keys.length}`);
    } catch {}
    Voice.onSpeechStart = () => setIsListening(true);
    Voice.onSpeechEnd = () => setIsListening(false);
    Voice.onSpeechResults = (event: any) => {
      if (event?.value && event.value[0]) {
        const text = event.value[0];
        setTranscript(text);
        if (currentExample !== null) {
          setExampleTranscripts((prev) => {
            const arr = [...prev];
            arr[currentExample] = text;
            return arr;
          });
        }
      }
    };

    Voice.onSpeechError = (event: any) => {
      setIsListening(false);
      const msg = event?.error?.message || event?.error || JSON.stringify(event || {});
      setLastVoiceError(String(msg));
      Alert.alert('Error de reconocimiento', String(msg));
    };

    return () => {
      try {
        // Primero remover listeners, luego destruir
        if (Voice && typeof Voice.removeAllListeners === 'function') {
          Voice.removeAllListeners();
        }
        if (Voice && typeof Voice.destroy === 'function') {
          Voice.destroy().catch(() => {});
        }
      } catch (error) {
        console.warn('Error durante limpieza de Voice:', error);
      }
    };
  }, []);

  const openWebRecognition = async (promptOverride?: string) => {
    const granted = await requestMicrophonePermission();
    if (!granted) {
      Alert.alert('Permiso requerido', 'Debes conceder acceso al micrÃ³fono para usar esta funciÃ³n.');
      return;
    }
    // Definir el texto objetivo a leer
    try {
      if (promptOverride) {
        setWebPromptText(promptOverride);
      } else if (currentExample !== null && prompts[currentExample]) {
        setWebPromptText(prompts[currentExample].audio);
      } else {
        // Texto genÃ©rico si no hay ejemplo seleccionado
        setWebPromptText('Di tu nombre, edad y de dÃ³nde eres.');
      }
    } catch { setWebPromptText(''); }
    setWebPercent(null);
    setWebMode(true);
  };

  const buildWebSpeechHTML = (promptText: string) => `
    <!DOCTYPE html>
    <html lang="es">
    <head>
      <meta charset="UTF-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <style>
        body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; padding: 16px; }
        .btn { padding: 10px 14px; border-radius: 8px; color: #fff; border: 0; margin-right: 8px; }
        .start { background: #1976d2; }
        .stop { background: #e53935; }
        .box { background: #f5f5f5; padding: 12px; border-radius: 8px; margin-top: 12px; }
        .prompt { background: #fff3e0; border-left: 4px solid #ff9800; padding: 10px; border-radius: 8px; margin-bottom: 12px; }
      </style>
    </head>
    <body>
      <h3>Reconocimiento Web (beta)</h3>
      <div class="prompt">
        <div style="font-weight:600; color:#ff9800; margin-bottom:6px;">Texto a leer</div>
        <div id="target">${promptText.replace(/</g,'&lt;')}</div>
      </div>
      <button class="btn start" id="start">Hablar / <span dir="rtl">ØªØ­Ø¯Ø«</span></button>
      <button class="btn stop" id="stop">Detener / <span dir="rtl">Ø¥ÙŠÙ‚Ø§Ù</span></button>
      <div class="box">
        <div id="status">Listo</div>
        <div id="out" style="margin-top:8px"></div>
      </div>
      <script>
        (function(){
          const RN = window.ReactNativeWebView;
          const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
          let rec = null;
          const status = document.getElementById('status');
          const out = document.getElementById('out');
          function send(type, payload){ try { RN.postMessage(JSON.stringify({ type, payload })); } catch(e) { /* noop */ } }
          if (!SR) {
            status.textContent = 'Web Speech API no disponible en este motor.';
            send('error', 'Web Speech API no disponible');
          } else {
            rec = new SR();
            rec.lang = 'es-ES';
            rec.interimResults = true;
            rec.maxAlternatives = 1;
            rec.onstart = function(){ status.textContent = 'Grabando...'; send('status', 'start'); };
            rec.onend = function(){ status.textContent = 'Detenido'; send('status', 'end'); };
            rec.onerror = function(e){ status.textContent = 'Error: ' + (e.error||''); send('error', e.error||'error'); };
            rec.onresult = function(e){
              let txt = '';
              for (let i = e.resultIndex; i < e.results.length; i++) {
                txt += e.results[i][0].transcript + ' ';
              }
              out.textContent = txt.trim();
              send('result', txt.trim());
            };
          }
          document.getElementById('start').onclick = function(){ try { rec && rec.start(); } catch(e) { send('error', String(e)); } };
          document.getElementById('stop').onclick = function(){ try { rec && rec.stop(); } catch(e) { send('error', String(e)); } };
        })();
      </script>
    </body>
    </html>
  `;

  const startListening = async (lang = 'es-ES') => {
    try {
      const granted = await requestMicrophonePermission();
      if (!granted) {
        Alert.alert('Permiso requerido', 'Debes conceder acceso al micrÃ³fono para usar esta funciÃ³n.');
        return;
      }
      // Intentar detener cualquier sesiÃ³n previa
      try { await Voice.stop(); } catch {}
      try { await Voice.destroy(); } catch {}
      // PequeÃ±o delay para asegurar estado listo
      await new Promise(res => setTimeout(res, 250));
      // Comprobar disponibilidad (manejar mÃ³dulo nulo)
      let isAvail = true;
      try {
        if ((Voice as any).isAvailable) {
          isAvail = await (Voice as any).isAvailable();
        }
      } catch (e: any) {
        // Caso tÃ­pico en Expo Go o si el mÃ³dulo nativo no estÃ¡ enlazado
        const msg = String(e?.message || e || '');
        if (msg.includes('isSpeechAvailable') || msg.includes('null')) {
          Alert.alert(
            'MÃ³dulo de voz no disponible',
            'Parece que la app se ejecuta en Expo Go o falta el mÃ³dulo nativo de reconocimiento de voz.\n\nSoluciones:\n- Usa un Dev Client o APK con EAS Build (no Expo Go).\n- AsegÃºrate de haber instalado @react-native-voice/voice y reconstruido la app.\n- En Android, verifica que la app de Google y Speech Services estÃ©n actualizadas.'
          );
          return;
        }
        isAvail = false;
      }
      if (!isAvail) {
        Alert.alert('No disponible', 'El reconocimiento de voz no estÃ¡ disponible en este dispositivo.');
        return;
      }
      setTranscript('');
      // Fallback de locales
      const locales = [lang, 'es-ES', 'es-US', 'es-AR', 'es-MX'];
      let started = false;
      for (const lc of locales) {
        try {
          const androidOpts: any = {
            EXTRA_LANGUAGE: lc,
            LANGUAGE: lc,
            EXTRA_MAX_RESULTS: 5,
            EXTRA_PARTIAL_RESULTS: true,
            EXTRA_SPEECH_INPUT_MINIMUM_LENGTH_MILLIS: 800,
            RECOGNIZER_ENGINE: 'Google',
          };
          await Voice.start(lc, androidOpts);
          started = true;
          break;
        } catch {}
      }
      if (!started) throw new Error('Voice.start failed');
      setIsListening(true);
    } catch (e) {
      setIsListening(false);
      Alert.alert(
        'MicrÃ³fono',
        'No se pudo iniciar el reconocimiento de voz. En Android, asegÃºrate de:\n\n- Conceder el permiso de micrÃ³fono\n- Tener la app de Google actualizada\n- Activar el servicio de reconocimiento de voz del dispositivo\n\nLuego, vuelve a intentarlo.'
      );
    }
  };

  const stopListening = async () => {
    try { await Voice.stop(); } catch {}
    setIsListening(false);
  };

  const diagnosticar = async () => {
    try {
      const granted = await requestMicrophonePermission();
      let isAvail = true;
      try {
        if ((Voice as any).isAvailable) {
          isAvail = await (Voice as any).isAvailable();
        }
      } catch (err: any) {
        // Detectar mÃ³dulo nulo
        const msg = String(err?.message || err || '');
        if (msg.includes('isSpeechAvailable') || msg.includes('null')) {
          Alert.alert(
            'MÃ³dulo de voz no disponible',
            'EstÃ¡s en Android, pero el mÃ³dulo nativo no responde.\n\nRevisa:\n- No uses Expo Go (usa Dev Client o APK/IPA).\n- Vuelve a construir la app tras instalar @react-native-voice/voice.\n- Actualiza la app de Google y Speech Services.'
          );
          return;
        }
        isAvail = false;
      }
      let started = false;
      let startedLocale = '';
      let lastErr: any = null;
      try { await Voice.stop(); } catch {}
      try { await Voice.destroy(); } catch {}
      await new Promise(res => setTimeout(res, 200));
      for (const lc of ['es-ES', 'es-US', 'es-AR', 'es-MX']) {
        try {
          await Voice.start(lc, { EXTRA_LANGUAGE: lc, LANGUAGE: lc, RECOGNIZER_ENGINE: 'Google' } as any);
          started = true; startedLocale = lc;
          try { await Voice.stop(); } catch {}
          break;
        } catch (err) { lastErr = err; }
      }
      // Intento de fallback sin opciones si aÃºn no arranca
      if (!started) {
        for (const lc of ['es-ES', 'es-US']) {
          try {
            await Voice.start(lc);
            started = true; startedLocale = lc;
            try { await Voice.stop(); } catch {}
            break;
          } catch (err2) { lastErr = err2; }
        }
      }
      const errMsg = lastErr ? (lastErr?.message || String(lastErr)) : 'â€”';
      Alert.alert('DiagnÃ³stico', `Permiso mic: ${granted ? 'OK' : 'DENEGADO'}\nDisponible: ${isAvail ? 'SÃ' : 'NO'}\nInicio de prueba: ${started ? 'OK' : 'FALLÃ“'}${started ? `\nLocale usado: ${startedLocale}` : ''}\nÃšltimo error: ${errMsg}`);
    } catch (e) {
      const m = (e as any)?.message || String(e);
      Alert.alert('DiagnÃ³stico', `Error durante el diagnÃ³stico: ${m}`);
    }
  };

  return (
    <View style={{ flex: 1 }}>
    <ScrollView style={styles.container}>
      {/* Header */}
      <View style={styles.header}>
        <TouchableOpacity style={styles.backButton} onPress={() => router.replace('/A1_Acceso')}>
          <Ionicons name="arrow-back" size={28} color="#1976d2" />
        </TouchableOpacity>
        <View style={styles.headerContent}>
          <Ionicons name="mic" size={50} color="#1976d2" />
          <Text style={styles.title}>ExpresiÃ³n Oral A1</Text>
          <Text style={styles.titleAr}>Ø§Ù„ØªØ¹Ø¨ÙŠØ± Ø§Ù„Ø´ÙÙˆÙŠ A1</Text>
          <Text style={styles.subtitle}>Practica hablando con guÃ­as y audios modelo</Text>
          <Text style={styles.subtitleAr}>ØªØ¯Ø±Ù‘Ø¨ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ø¯Ø« Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥Ø±Ø´Ø§Ø¯Ø§Øª ÙˆÙ†Ù…Ø§Ø°Ø¬ ØµÙˆØªÙŠØ©</Text>
          {!!nativeInfo && (
            <Text style={{ fontSize: 12, color: '#999', textAlign: 'center', marginTop: 6 }}>Debug: {nativeInfo}</Text>
          )}
        </View>
      </View>

      {/* Consejos */}
      <View style={styles.section}>
        <Text style={styles.sectionTitle}>Consejos de prÃ¡ctica</Text>
        <Text style={styles.sectionTitleAr}>Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØªØ¯Ø±ÙŠØ¨</Text>
        <View style={styles.tipsBox}>
          <Text style={styles.tip}>â€¢ Habla en voz alta 2-3 veces cada respuesta.</Text>
          <Text style={styles.tip}>â€¢ Imitar el ritmo del audio y la pronunciaciÃ³n.</Text>
          <Text style={styles.tip}>â€¢ Usa conectores: y, pero, porque.</Text>
          <Text style={styles.tipAr}>â€¢ ØªÙƒÙ„Ù‘Ù… Ø¨ØµÙˆØª Ø¹Ø§Ù„Ù 2-3 Ù…Ø±Ø§Øª Ù„ÙƒÙ„ Ø¥Ø¬Ø§Ø¨Ø©.</Text>
          <Text style={styles.tipAr}>â€¢ Ù‚ÙÙ… Ø¨ØªÙ‚Ù„ÙŠØ¯ Ø¥ÙŠÙ‚Ø§Ø¹ Ø§Ù„ØµÙˆØª ÙˆØ§Ù„Ù†Ø·Ù‚.</Text>
          <Text style={styles.tipAr}>â€¢ Ø§Ø³ØªØ®Ø¯Ù… Ø±ÙˆØ§Ø¨Ø·: ÙˆØŒ Ù„ÙƒÙ†ØŒ Ù„Ø£Ù†.</Text>
        </View>
        {/* Aviso eliminado para UI limpia */}
      </View>

      {/* Actividades guiadas */}
      <View style={styles.section}>
        <Text style={styles.sectionTitle}>Lee el texto y comprueba tu espaÃ±ol en el resultado de coincidencia</Text>
        <Text style={styles.sectionTitleAr}>Ø£Ù†Ø´Ø·Ø© Ù…ÙˆØ¬Ù‡Ø©</Text>

        {/* Bloque de micrÃ³fono eliminado para UI minimalista */}

        {prompts.map((p, i) => (
          <View key={i} style={styles.promptCard}>
            <View style={styles.promptHeader}>
              <View style={{ flex: 1 }}>
                <Text style={styles.promptEs}>{p.es}</Text>
                <Text style={styles.promptAr}>{p.ar}</Text>
              </View>
              {/* Botones de audio eliminados para UI minimalista */}
            </View>

            <View style={styles.exampleBox}>
              <Text style={styles.exampleTitle}>Modelo</Text>
              <Text style={styles.exampleText}>{p.audio}</Text>
            </View>

            {/* PrÃ¡ctica por ejemplo: lee en voz alta */}
            <View style={styles.micRow}>
              {!isListening ? (
                <TouchableOpacity
                  style={[styles.micButton, { backgroundColor: '#1976d2' }]}
                  onPress={() => {
                    setCurrentExample(i);
                    openWebRecognition(p.audio);
                  }}
                >
                  <Ionicons name="mic" size={20} color="#fff" style={{ marginRight: 6 }} />
                  <Text style={styles.micButtonText}>Hablar{"\n"}<Text style={{ fontSize: 12, writingDirection: 'rtl' }}>ØªØ­Ø¯Ø«</Text></Text>
                </TouchableOpacity>
              ) : (
                <TouchableOpacity style={[styles.micButton, { backgroundColor: '#e53935' }]} onPress={stopListening}>
                  <Ionicons name="mic-off" size={20} color="#fff" style={{ marginRight: 6 }} />
                  <Text style={styles.micButtonText}>Detener{"\n"}<Text style={{ fontSize: 12, writingDirection: 'rtl' }}>Ø¥ÙŠÙ‚Ø§Ù</Text></Text>
                </TouchableOpacity>
              )}
              {compatMode && (
                <TouchableOpacity
                  style={[styles.micButton, { backgroundColor: '#607d8b' }]}
                  onPress={() => {
                    // En modo compatibilidad, dar por leÃ­do: usamos el modelo como transcripciÃ³n del usuario
                    const arr = [...exampleTranscripts];
                    arr[i] = p.audio;
                    setExampleTranscripts(arr);
                    if (currentExample === i) setTranscript(p.audio);
                    Alert.alert('Marcado', 'Ejercicio marcado como leÃ­do (modo compatibilidad).');
                  }}
                >
                  <Ionicons name="checkmark" size={18} color="#fff" style={{ marginRight: 6 }} />
                  <Text style={styles.micButtonText}>Marcar leÃ­do (compat.)</Text>
                </TouchableOpacity>
              )}
            </View>
            <View style={styles.transcriptBox}>
              <Text style={styles.transcriptLabel}>Tu transcripciÃ³n:</Text>
              <Text style={styles.transcriptText}>{exampleTranscripts[i] || 'â€”'}</Text>
              <Text style={[styles.transcriptLabel, { marginTop: 6 }]}>Coincidencia: {scoreSimilarity(exampleTranscripts[i] || '', p.audio)}%</Text>
            </View>

            <View style={styles.speakingHints}>
              <Text style={styles.hint}>Repite el modelo en voz alta. Luego intenta decir 1 frase extra (por ejemplo: dÃ³nde, cuÃ¡ndo, con quiÃ©n).</Text>
              <Text style={styles.hintAr}>Ø£Ø¹Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨ØµÙˆØª Ø¹Ø§Ù„Ù. Ø«Ù… Ø­Ø§ÙˆÙ„ Ø¥Ø¶Ø§ÙØ© Ø¬Ù…Ù„Ø© Ø£Ø®Ø±Ù‰ (Ù…Ø«Ù„Ø§Ù‹: Ø£ÙŠÙ†ØŒ Ù…ØªÙ‰ØŒ Ù…Ø¹ Ù…Ù†).</Text>
            </View>
          </View>
        ))}

        {/* El examen oral finaliza automÃ¡ticamente */}

        {/* Tarjeta 'Objetivo' eliminada */}
      </View>
    </ScrollView>
    {/* Modal WebView Reconocimiento Web */}
    <Modal visible={webMode} animationType="slide" onRequestClose={() => setWebMode(false)}>
      <View style={{ flex: 1 }}>
        <View style={{ flexDirection: 'row', alignItems: 'center', justifyContent: 'space-between', padding: 10, backgroundColor: '#3f51b5' }}>
          <TouchableOpacity onPress={() => setWebMode(false)}>
            <Ionicons name="close" size={24} color="#fff" />
          </TouchableOpacity>
          <Text style={{ color: '#fff', fontWeight: 'bold' }}>Reconocimiento Web (beta)</Text>
          <View style={{ width: 24 }} />
        </View>
        {/* Texto objetivo visible tambiÃ©n fuera de la WebView */}
        {!!webPromptText && (
          <View style={{ padding: 10, backgroundColor: '#fff3e0' }}>
            <Text style={{ color: '#ff6f00', fontWeight: 'bold', marginBottom: 4 }}>Texto a leer</Text>
            <Text style={{ color: '#333' }}>{webPromptText}</Text>
          </View>
        )}
        <WebView
          originWhitelist={["*"]}
          source={{ html: buildWebSpeechHTML(webPromptText) }}
          onMessage={(event) => {
            try {
              const data = JSON.parse(event.nativeEvent.data || '{}');
              if (data?.type === 'result') {
                const txt = String(data.payload || '');
                setTranscript(txt);
                if (currentExample !== null) {
                  setExampleTranscripts((prev) => { const arr = [...prev]; arr[currentExample] = txt; return arr; });
                }
                try { setWebPercent(scoreSimilarity(txt, webPromptText)); } catch {}
              } else if (data?.type === 'error') {
                Alert.alert('Reconocimiento web', String(data.payload || 'Error'));
              }
            } catch {}
          }}
          // Conceder permisos de micrÃ³fono dentro de la WebView (Android)
          onPermissionRequest={(e: any) => {
            // @ts-ignore: RN WebView types
            try { e.grant(e.resources); } catch {}
          }}
        />
        {/* Porcentaje en tiempo real */}
        <View style={{ paddingVertical: 16, backgroundColor: '#fff', alignItems: 'center' }}>
          {typeof webPercent === 'number' && (
            <>
              {webPercent === 100 ? (
                <Text style={{ fontSize: 18, fontWeight: '600', color: '#2e7d32', marginBottom: 6 }}>Â¡Enhorabuena!</Text>
              ) : (
                <>
                  <Text style={{ fontSize: 18, fontWeight: '600', color: '#c62828' }}>Sigue intentando</Text>
                  <Text style={{ fontSize: 16, color: '#c62828', writingDirection: 'rtl', marginBottom: 6 }}>ÙˆØ§ØµÙ„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©</Text>
                </>
              )}
              <Text style={{ fontSize: 48, marginBottom: 6 }}>
                {webPercent === 100 ? 'ğŸ˜„' : (webPercent >= 50 ? 'ğŸ™‚' : 'ğŸ˜')}
              </Text>
              <Text style={{ fontSize: 56, fontWeight: 'bold', color: webPercent >= 70 ? '#2e7d32' : '#c62828' }}>{webPercent}%</Text>
            </>
          )}
        </View>
        <View style={{ padding: 12, backgroundColor: '#fff' }}>
          <TouchableOpacity
            style={{ backgroundColor: '#1976d2', paddingVertical: 12, borderRadius: 8, alignItems: 'center' }}
            onPress={() => { setWebMode(false); }}
          >
            <Text style={{ color: '#fff', fontWeight: 'bold' }}>Comprobar</Text>
          </TouchableOpacity>
        </View>
      </View>
    </Modal>
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#f5f7fa',
  },
  header: {
    backgroundColor: '#fff',
    paddingTop: 50,
    paddingBottom: 20,
    paddingHorizontal: 20,
    borderBottomWidth: 1,
    borderBottomColor: '#e9ecef',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.1,
    shadowRadius: 4,
    elevation: 3,
  },
  backButton: {
    position: 'absolute',
    top: 50,
    left: 20,
    zIndex: 1,
  },
  headerContent: {
    alignItems: 'center',
    marginTop: 20,
  },
  title: {
    fontSize: 24,
    fontWeight: 'bold',
    color: '#333',
    textAlign: 'center',
    marginBottom: 4,
  },
  titleAr: {
    fontSize: 20,
    fontWeight: 'bold',
    color: '#666',
    textAlign: 'center',
    marginBottom: 8,
    writingDirection: 'rtl',
  },
  subtitle: {
    fontSize: 16,
    color: '#666',
    textAlign: 'center',
    marginBottom: 4,
  },
  subtitleAr: {
    fontSize: 14,
    color: '#888',
    textAlign: 'center',
    writingDirection: 'rtl',
  },
  section: {
    backgroundColor: '#fff',
    borderRadius: 12,
    padding: 20,
    margin: 20,
    marginBottom: 12,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 1 },
    shadowOpacity: 0.05,
    shadowRadius: 3,
    elevation: 2,
  },
  sectionTitle: {
    fontSize: 20,
    fontWeight: 'bold',
    color: '#1976d2',
    marginBottom: 8,
  },
  sectionTitleAr: {
    fontSize: 18,
    fontWeight: 'bold',
    color: '#666',
    marginBottom: 16,
    textAlign: 'right',
    writingDirection: 'rtl',
  },
  sectionText: {
    fontSize: 16,
    color: '#333',
    lineHeight: 24,
    marginBottom: 12,
  },
  sectionTextAr: {
    fontSize: 14,
    color: '#666',
    lineHeight: 22,
    textAlign: 'right',
    writingDirection: 'rtl',
  },
  micBox: {
    backgroundColor: '#eef6ff',
    borderLeftWidth: 4,
    borderLeftColor: '#1976d2',
    padding: 12,
    borderRadius: 10,
    marginBottom: 12,
  },
  micTitle: {
    fontSize: 14,
    color: '#1976d2',
    marginBottom: 8,
    fontWeight: '600',
  },
  micRow: {
    flexDirection: 'row',
    alignItems: 'center',
    gap: 10,
    marginBottom: 10,
  },
  micButton: {
    flexDirection: 'row',
    alignItems: 'center',
    paddingHorizontal: 14,
    paddingVertical: 10,
    borderRadius: 20,
  },
  micButtonText: {
    color: '#fff',
    fontWeight: 'bold',
  },
  transcriptBox: {
    backgroundColor: '#fff',
    borderRadius: 8,
    padding: 10,
    borderWidth: 1,
    borderColor: '#e0e0e0',
  },
  transcriptLabel: {
    fontSize: 12,
    color: '#666',
    marginBottom: 4,
  },
  transcriptText: {
    fontSize: 16,
    color: '#333',
  },
  tipsBox: {
    backgroundColor: '#f8f9fa',
    padding: 14,
    borderRadius: 10,
  },
  tip: {
    fontSize: 14,
    color: '#333',
    marginBottom: 6,
  },
  tipAr: {
    fontSize: 13,
    color: '#666',
    marginBottom: 4,
    textAlign: 'right',
    writingDirection: 'rtl',
  },
  promptCard: {
    backgroundColor: '#f8f9fa',
    padding: 16,
    borderRadius: 10,
    marginBottom: 12,
  },
  promptHeader: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'space-between',
    marginBottom: 10,
  },
  promptEs: {
    fontSize: 16,
    fontWeight: 'bold',
    color: '#1976d2',
  },
  promptAr: {
    fontSize: 14,
    color: '#666',
    writingDirection: 'rtl',
  },
  exampleBox: {
    backgroundColor: '#fff3e0',
    borderLeftWidth: 4,
    borderLeftColor: '#ff9800',
    padding: 10,
    borderRadius: 8,
  },
  exampleTitle: {
    fontSize: 14,
    fontWeight: 'bold',
    color: '#ff9800',
    marginBottom: 4,
  },
  exampleText: {
    fontSize: 14,
    color: '#333',
  },
  speakingHints: {
    marginTop: 10,
  },
  hint: {
    fontSize: 13,
    color: '#333',
  },
  hintAr: {
    fontSize: 12,
    color: '#666',
    textAlign: 'right',
    writingDirection: 'rtl',
  },
  finishButton: {
    marginTop: 10,
    backgroundColor: '#388e3c',
    paddingVertical: 12,
    paddingHorizontal: 16,
    borderRadius: 10,
    alignSelf: 'center',
    flexDirection: 'row',
    alignItems: 'center',
  },
  finishButtonText: {
    color: '#fff',
    fontSize: 16,
    fontWeight: 'bold',
  },
});

// EvalÃºa la coincidencia por palabras entre el modelo y la transcripciÃ³n del usuario
function scoreSimilarity(user: string, model: string): number {
  const norm = (s: string) => (s || '')
    .toLowerCase()
    .normalize('NFC')
    .replace(/[^a-zÃ¡Ã©Ã­Ã³ÃºÃ¼Ã±\s]/g, '')
    .trim();
  const u = norm(user).split(/\s+/).filter(Boolean);
  const m = norm(model).split(/\s+/).filter(Boolean);
  if (m.length === 0) return 0;
  let hits = 0;
  const setU = new Set(u);
  for (const w of m) if (setU.has(w)) hits++;
  return Math.min(100, Math.round((hits / m.length) * 100));
}

// FunciÃ³n para verificar si el usuario completÃ³ suficientes ejercicios con buena puntuaciÃ³n
const checkOralCompletion = async (prompts: any[], exampleTranscripts: string[]) => {
  try {
    // Verificar si ya estÃ¡ aprobado
    const alreadyPassed = await AsyncStorage.getItem('A1_oral_gate_passed');
    if (alreadyPassed === 'true') {
      return true;
    }

    // Contar cuÃ¡ntos ejercicios tienen buena puntuaciÃ³n (â‰¥70%)
    let goodScores = 0;
    let completedExercises = 0;
    const requiredGoodScores = 5; // Requiere al menos 5 ejercicios con buena puntuaciÃ³n
    const totalExercises = prompts.length;

    for (let i = 0; i < totalExercises; i++) {
      const userTranscript = exampleTranscripts[i] || '';
      if (userTranscript) {
        completedExercises++;
        const score = scoreSimilarity(userTranscript, prompts[i].audio);
        if (score >= 70) {
          goodScores++;
        }
      }
    }

    // Actualizar el progreso del examen oral
    const progress = Math.round((completedExercises / totalExercises) * 100);
    await AsyncStorage.setItem('A1_oral_progress', progress.toString());

    return goodScores >= requiredGoodScores;
  } catch (error) {
    console.error('Error checking oral completion:', error);
    return false;
  }
};

// FunciÃ³n para actualizar el progreso del examen oral
const updateOralProgress = async (completed: number, total: number) => {
  try {
    const progress = Math.round((completed / total) * 100);
    await AsyncStorage.setItem('A1_oral_progress', progress.toString());
    return progress;
  } catch (error) {
    console.error('Error al actualizar el progreso del examen oral:', error);
    return 0;
  }
};

// FunciÃ³n para finalizar el examen oral
const finalizarExamenOral = async (prompts: any[], exampleTranscripts: string[], router: any) => {
  try {
    const completed = await checkOralCompletion(prompts, exampleTranscripts);

    if (completed) {
      // Marcar como aprobado
      await AsyncStorage.setItem('A1_oral_gate_passed', 'true');

      Alert.alert(
        'Â¡Examen Oral Aprobado!',
        'Has completado exitosamente el examen oral. Ahora puedes acceder al examen escrito.',
        [
          {
            text: 'Continuar al Examen Escrito',
            onPress: () => router.push('/A1_Acceso/clases/ExamenOralGateway')
          }
        ]
      );
    } else {
      // No mostrar alerta de pendiente, solo continuar practicando
      return false;
    }
  } catch (error) {
    Alert.alert('Error', 'Hubo un problema al procesar el examen oral.');
  }
};
